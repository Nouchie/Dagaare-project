{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2w0mPkxBLMUP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/dagaare_words_definition/')\n",
        "dagaare_Tokenizer= \"/content/Transformer.py\"\n",
        "english_file = \"/content/drive/MyDrive/dagaare_words_definition/dagaare_definition_sentences.txt\"\n",
        "dagaare_file = \"/content/drive/MyDrive/dagaare_words_definition/dagaare_words_sentences.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pLrermwELlIQ"
      },
      "outputs": [],
      "source": [
        "from Transformer import Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dMbTNGzLUm5"
      },
      "outputs": [],
      "source": [
        "START_TOKEN = '<START>'\n",
        "PADDING_TOKEN = '<PADDING>'\n",
        "END_TOKEN = '<END>'\n",
        "\n",
        "dagaare_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/',\n",
        "                      '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '<', '=', '>', '?', 'ˌ',\n",
        "                      'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L',\n",
        "                        'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X',\n",
        "                        'Y', 'Z',\n",
        "                        '[', '\\\\', ']', '^', '_', '`',\n",
        "                        'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
        "                        'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x',\n",
        "                        'y', 'z','à','á','â','ã','æ','è','é','ì','í','ò','ó','õ','ù','ú','û','ĩ','ŋ','ŏ','ũ',\n",
        "                        'Ɔ','Ɛ','ǎ','ɔ','ɛ','ɡ','ɪ','ʊ','ʋ','ͻ','ε','ṹ','ạ','ẽ','ὸ','ό',\n",
        "                        '{', '|', '}', '~', PADDING_TOKEN, END_TOKEN]\n",
        "\n",
        "english_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/',\n",
        "                        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
        "                        ':', '<', '=', '>', '?', '@',\n",
        "                        'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L',\n",
        "                        'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X',\n",
        "                        'Y', 'Z',\n",
        "                        '[', '\\\\', ']', '^', '_', '`',\n",
        "                        'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
        "                        'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x',\n",
        "                        'y', 'z',\n",
        "                        '{', '|', '}', '~', PADDING_TOKEN, END_TOKEN]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytbVEiKXLzpe"
      },
      "outputs": [],
      "source": [
        "index_to_dagaare = {k:v for k,v in enumerate(dagaare_vocabulary)}\n",
        "dagaare_to_index = {v:k for k,v in enumerate(dagaare_vocabulary)}\n",
        "index_to_english = {k:v for k,v in enumerate(english_vocabulary)}\n",
        "english_to_index = {v:k for k,v in enumerate(english_vocabulary)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWLgl7ofL4Ki"
      },
      "outputs": [],
      "source": [
        "with open(english_file, 'r') as file:\n",
        "    english_sentences = file.readlines()\n",
        "with open(dagaare_file, 'r') as file:\n",
        "    dagaare_sentences = file.readlines()\n",
        "\n",
        "# Limit Number of sentences\n",
        "TOTAL_SENTENCES = 200000\n",
        "english_sentences = english_sentences[:TOTAL_SENTENCES]\n",
        "dagaare_sentences = dagaare_sentences[:TOTAL_SENTENCES]\n",
        "english_sentences = [sentence.rstrip('\\n').lower() for sentence in english_sentences]\n",
        "dagaare_sentences = [sentence.rstrip('\\n') for sentence in dagaare_sentences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJZCicCVL7QI",
        "outputId": "74a2f553-27bd-4ffd-9908-87baaf346b7f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['definition',\n",
              " '(1) and',\n",
              " '(2) in order to',\n",
              " 'but',\n",
              " 'they',\n",
              " 'the',\n",
              " 'to hate',\n",
              " 'expression of surprise and regret',\n",
              " 'expression of regret',\n",
              " 'expression expressing “i told you so.”']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "english_sentences[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoLx7ukTL9a9",
        "outputId": "1db45bfa-b431-4885-b2a6-06846febb56b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Word', 'a', 'a', 'a', 'a', 'a', 'a', 'aa', 'aa', 'aa']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dagaare_sentences[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ru4onq-WL_pq",
        "outputId": "e8c57686-ecc0-411d-e897-20dfe05962ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "97th percentile length dagaare: 21.0\n",
            "97th percentile length English: 75.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "PERCENTILE = 97\n",
        "print( f\"{PERCENTILE}th percentile length dagaare: {np.percentile([len(x) for x in dagaare_sentences], PERCENTILE)}\" )\n",
        "print( f\"{PERCENTILE}th percentile length English: {np.percentile([len(x) for x in english_sentences], PERCENTILE)}\" )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUDitpfXMBuc",
        "outputId": "add165f5-39e2-4061-bbf5-fb8756cce0c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of sentences: 8112\n",
            "Number of valid sentences: 7209\n"
          ]
        }
      ],
      "source": [
        "max_sequence_length = 200\n",
        "\n",
        "def is_valid_tokens(sentence, vocab):\n",
        "    for token in list(set(sentence)):\n",
        "        if token not in vocab:\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def is_valid_length(sentence, max_sequence_length):\n",
        "    return len(list(sentence)) < (max_sequence_length - 1) # need to re-add the end token so leaving 1 space\n",
        "\n",
        "valid_sentence_indicies = []\n",
        "for index in range(len(dagaare_sentences)):\n",
        "    dagaare_sentence, english_sentence = dagaare_sentences[index], english_sentences[index]\n",
        "    if is_valid_length(dagaare_sentence, max_sequence_length) \\\n",
        "      and is_valid_length(english_sentence, max_sequence_length) \\\n",
        "      and is_valid_tokens(dagaare_sentence, dagaare_vocabulary):\n",
        "        valid_sentence_indicies.append(index)\n",
        "\n",
        "print(f\"Number of sentences: {len(dagaare_sentences)}\")\n",
        "print(f\"Number of valid sentences: {len(valid_sentence_indicies)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQEJcXVWMDLF"
      },
      "outputs": [],
      "source": [
        "dagaare_sentences = [dagaare_sentences[i] for i in valid_sentence_indicies]\n",
        "english_sentences = [english_sentences[i] for i in valid_sentence_indicies]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Lbcqw08NI8T"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "\n",
        "# Function to remove punctuation marks and special characters from text\n",
        "def remove_special_characters(text):\n",
        "    special_chars = ['“','́','…','\\t','–', '”','•', '’','‘','æ','ɪ','ạ', 'à', 'á', 'â', 'ã', 'è', 'é', 'ì', 'í', 'ò', 'ó', 'õ', 'ù', 'ú', 'û', 'ĩ', 'ŋ', 'ŏ', 'ũ', 'Ɔ', 'Ɛ', 'ǎ', 'ɔ', 'ɛ', 'ɡ', 'ʊ', 'ʋ', 'ͻ', 'ε', 'ṹ', 'ẽ', 'ὸ', 'ό']\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    cleaned_text = text.translate(translator)\n",
        "    for char in special_chars:\n",
        "        cleaned_text = cleaned_text.replace(char, 'UNK')\n",
        "    return cleaned_text\n",
        "\n",
        "# Paths to the English and Dagaare files\n",
        "english_file = \"/content/drive/MyDrive/dagaare_words_definition/dagaare_definition_sentences.txt\"\n",
        "dagaare_file = \"/content/drive/MyDrive/dagaare_words_definition/dagaare_words_sentences.txt\"\n",
        "\n",
        "# Read the contents of the English and Dagaare files\n",
        "with open(english_file, 'r', encoding='utf-8') as f:\n",
        "    english_sentences = f.readlines()\n",
        "\n",
        "with open(dagaare_file, 'r', encoding='utf-8') as f:\n",
        "    dagaare_sentences = f.readlines()\n",
        "\n",
        "# Limit Number of sentences\n",
        "TOTAL_SENTENCES = 500000\n",
        "english_sentences = english_sentences[:TOTAL_SENTENCES]\n",
        "dagaare_sentences = dagaare_sentences[:TOTAL_SENTENCES]\n",
        "\n",
        "# Remove special characters and strip newline characters from English and Dagaare sentences\n",
        "english_sentences = [remove_special_characters(sentence.rstrip('\\n')) for sentence in english_sentences]\n",
        "dagaare_sentences = [sentence.rstrip('\\n') for sentence in dagaare_sentences]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hr_TKxHqMDHR",
        "outputId": "3723b94c-a606-4d30-ecee-d0119ced4cd7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Word', 'a', 'a']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dagaare_sentences[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMffh9HvMDFV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "d_model = 512\n",
        "batch_size = 30\n",
        "ffn_hidden = 2048\n",
        "num_heads = 8\n",
        "drop_prob = 0.1\n",
        "num_layers = 1\n",
        "max_sequence_length = 1000\n",
        "dg_vocab_size = len(dagaare_vocabulary)\n",
        "\n",
        "transformer = Transformer(d_model,\n",
        "                          ffn_hidden,\n",
        "                          num_heads,\n",
        "                          drop_prob,\n",
        "                          num_layers,\n",
        "                          max_sequence_length,\n",
        "                          dg_vocab_size,\n",
        "                          english_to_index,\n",
        "                          dagaare_to_index,\n",
        "                          START_TOKEN,\n",
        "                          END_TOKEN,\n",
        "                          PADDING_TOKEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7loFOFjMDDB",
        "outputId": "b6b224b2-d72f-42a9-a8cc-7d59a18f3afa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): Encoder(\n",
              "    (sentence_embedding): SentenceEmbedding(\n",
              "      (embedding): Embedding(97, 512)\n",
              "      (position_encoder): PositionalEncoding()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (layers): SequentialEncoder(\n",
              "      (0): EncoderLayer(\n",
              "        (attention): MultiHeadAttention(\n",
              "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (norm1): LayerNormalization()\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (ffn): PositionwiseFeedForward(\n",
              "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (relu): ReLU()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (norm2): LayerNormalization()\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (sentence_embedding): SentenceEmbedding(\n",
              "      (embedding): Embedding(132, 512)\n",
              "      (position_encoder): PositionalEncoding()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (layers): SequentialDecoder(\n",
              "      (0): DecoderLayer(\n",
              "        (self_attention): MultiHeadAttention(\n",
              "          (qkv_layer): Linear(in_features=512, out_features=1536, bias=True)\n",
              "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (layer_norm1): LayerNormalization()\n",
              "        (dropout1): Dropout(p=0.1, inplace=False)\n",
              "        (encoder_decoder_attention): MultiHeadCrossAttention(\n",
              "          (kv_layer): Linear(in_features=512, out_features=1024, bias=True)\n",
              "          (q_layer): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (layer_norm2): LayerNormalization()\n",
              "        (dropout2): Dropout(p=0.1, inplace=False)\n",
              "        (ffn): PositionwiseFeedForward(\n",
              "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
              "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "          (relu): ReLU()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (layer_norm3): LayerNormalization()\n",
              "        (dropout3): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (linear): Linear(in_features=512, out_features=132, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOar4ab6MDAx"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "\n",
        "    def __init__(self, english_sentences, dagaare_sentences):\n",
        "        self.english_sentences = english_sentences\n",
        "        self.dagaare_sentences = dagaare_sentences\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.english_sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.english_sentences[idx], self.dagaare_sentences[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdIEmc4NMC-w"
      },
      "outputs": [],
      "source": [
        "dataset = TextDataset(english_sentences, dagaare_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aInq6s7UMC8h",
        "outputId": "63cb0421-5fcf-4578-ce2a-89e7a95e37cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8112"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5pEhHijMOxR",
        "outputId": "9c82426a-615d-4331-c80f-e07ff49e9a31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('1 and', 'a')"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmwG7pItMOuY"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(dataset, batch_size)\n",
        "iterator = iter(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ea_vmlfqMOsT",
        "outputId": "e36766b1-d11f-4e77-8312-33efc5d226ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('Definition', '1 and', '2 in order to', 'but', 'they', 'the', 'to hate', 'expression of surprise and regret', 'expression of regret', 'expression expressing UNKI told you soUNK', 'expression of pain', '1 expression of disapproval', '1 yes answer to a call', 'is that so expression of uncertain surprise', 'answer in agreement', 'expression of lack of confidence in someoneUNKs ability to perform a task', 'expression of total despair', 'infertile woman ', 'well then', '1 expression of despair over a repeated mishap', '1 exclamation of satisfaction or commendation', '1 palm tree 2 palm fruit', 'palm fruit', 'palm wine', 'palm oil', 'palmfrond broom', 'palm tree', 'which ones nonhuman', 'Africa', 'African'), ('Word', 'a', 'a', 'a', 'a', 'a', 'a', 'aa', 'aa', 'aa', 'aae', 'a-a', 'ãa', 'ãaa', 'âaa', 'aa-ee', 'aa-hii', 'aane', 'aaŋ', 'aba', 'abaa', 'abɛ', 'abɛbiri', 'abɛdãã', 'abɛkãã', 'abɛsaare', 'abɛteɛ', 'abuobo', 'Afereka', 'Aferekaneɛ')]\n",
            "[('preface of a book', '1 to dance 2 to jump up and down', '1 to fly 2 erect', 'to ask for permission to join someone knock door', 'a type of silky', 'bad luck', 'thatUNKs right expression of agreement', 'an expression that denotes UNKwellUNK', 'no', 'an expression of despair', 'expression of boastful challenge', 'expression of disappointment at failure', 'expression of disgust and disagreement', 'expression of despair', 'The thieves have robbed my friend again', 'emphatic form of aku', 'expression indicating oneUNKs inability to do a task', 'God', 'I swear', 'in the name of God', 'to open ring', 'expression ordering one to get out away with you', 'metaphor literature', 'expression of surprise mixed with fear', 'hello', 'aeroplane', 'airport', 'but', 'these 3rd person plural demonstrative nonhuman', 'a type of small tree with large leaves and pink fruit'), ('afu', 'age', 'age', 'agoo', 'agoo', 'agye', 'ahâa', 'ahaŋ', 'ai', 'aii', 'akaase', 'akaasemanakei', 'akaase akai', 'aku', 'akuroku', 'akuroku', 'akuu', 'Ala', 'ala', 'alaakosebaroo', 'ale', 'alee', 'aleɛma', 'alɛ', 'aloo', 'aloopelee', 'aloopeleeduoraa', 'ama', 'ama', 'ambaŋenaa')]\n",
            "[('America', '1 perhaps', 'much more than exaggeration', 'thanks', 'those 3rd person plural strong form nonhuman', 'four', 'because', 'reason', 'those ones 3rd person plural demonstrative', 'it a problem', '1 world 2 people of the world', '1 and 2 although', 'despite', 'effort', 'welcome an expression of goodwill to a stranger who has just arrived', 'gratitude', 'eight', '1 a traditional womenUNKs dance 2 music for such a dance', 'who which person interrogative pronoun', 'before', '1 a type of edible berry that turns violet when ripe 2 the tree of this fruit', 'a woman who has recently given birth', 'noon used as a greeting', 'five', 'one who is great or strong physically or spiritually', 'to be alerted used to caution or persuade', 'who interrogative pronoun', 'no one retort implies the matter is none of the askerUNKs business', 'like', 'having the blades burnt away'), ('Ameleka', 'aminekaŋa', 'amma', 'ammeseɛrɛ', 'ana', 'anaare', 'ananso', 'ananso', 'anaŋ', 'anaŋ', 'andonɛɛ', 'ane', 'aneazaa', 'aneɛ', 'anesɛ', 'angyoɔso', 'anii', 'anlee', 'annoo', 'ansaŋ', 'ansiŋinee', 'ansoɔnee', 'antere', 'anuu', 'anwoŋ', 'aŋ', 'aŋ', 'aŋa', 'aŋa', 'aŋgaara')]\n",
            "[('a type of long grass used to weave sleeping mats', 'to adorn', 'Accra', 'river blindness', 'barrel', 'of course expression of certainty', 'expression of unpleasant surprise', 'emphatic expression of despair', 'to gather up oneUNKs courage', 'kidney', 'to cut', 'to be related through the motherUNKs line', '1 to stand 2 to wait UNK N baUNK ka o na are la ka N gaa te pUNKge o I know she will wait so that I go to meet himher 3 to stop UNK A wUNKUNKkye kyUNKUNKUNKUNK la tasoga tasoga leUNK are The watch worked for a while and then stopped', 'to tear off from the main body branch or limb of an animal', 'maternal uncle', 'eldest niece', 'nephew or niece', 'arithmetic', '1 standing place', '1 standing place position 2', 'not negative particle', '1 they', 'to fix a pointed object firmly in the ground', 'to gallop', '1 father 2 friend between males 3 Mister', 'or normally used in question tag', 'dog', 'a small black ground antlike creature which burrows into the ground with the tip of its abdomen', 'a type of childrenUNKs game', 'body of water'), ('aŋgeli', 'aŋgoɔle', 'Aŋkara', 'aŋko', 'aŋkorɔ', 'ão', 'apa', 'aparapa', 'ara', 'arambiri', 'are', 'are', 'are', 'are', 'areba', 'arekpoŋ', 'arelee', 'aremateke', 'arezie', 'aroozie', 'ba', 'ba', 'ba', 'ba', 'ba', 'baa', 'baa', 'baa', 'baa', 'baa')]\n",
            "[('1 to grow up', 'father familiar term of address used by toddlers', 'Bible', 'bustard', 'goodbye', 'bag', 'patient', '1 slim', 'to ache slightly disconfort of the stomach UNK Ka maaUNK iri ba gaa bangyeraa n poUNK maUNK baala la If I donUNKt go to the toilet for the day I normally have a slight stomachache baalUNKUNK', 'to separate grains from unwanted material UNK A pUNKge baale iri la a seUNKkUNKabie yi a pUNKgere poUNK The woman separated the groundnuts from the shells baalUNKUNK', 'hospital', 'the act of supporting someone by holding them by the midsection UNK Ba kpUNK la a baala baalimbo gaa ne a asibiti They supported the patient by the midsection and took him to the hospital', 'germ', 'feast organised for a friend UNK Te daare gaa la baalomboUNKlaa Loraa poUNK We attended a friendship feast in Lawra', 'contagious disease', 'recurring illness', 'friendship UNK Ba nyUNKge la baaloUNK saUNKa zaa They have been friends for a long time', 'illness', '1 calm UNK ZenUNK', '1 gallon measure 2 balloon', 'Ursa Major constellation also known as Big Dipper', 'lily pads pl sg baapUNKmpUNKloo pl baapUNKmpUNKlUNK 2pl baapUNKmpUNKUNKbaapUNKmpUNKllUNKUNK', 'end', '1 to finish', '1 a seed from a type of tree 2 a type of large bead made from this seed', 'Baasare ethnic group', 'bicycle', 'a type of tree that resembles the shea nut tree', 'ignorance', 'one who is innocent'), ('baa', 'baabaa', 'Baabol', 'bãabõo', 'baaebaae', 'baage', 'baala', 'baalaa', 'baale', 'baale', 'baalebayiri', 'baalimbo', 'baalombiri', 'baalomboɔlaa', 'baalonlɔnnaa', 'baalonnooraa', 'baaloŋ', 'baaloŋ', 'baaloŋ', 'baaluu', 'baa-ne-ŋmaaŋa', 'baapɛmpɛle', 'baaraa', 'baare', 'baasaabiri', 'Baasaale', 'baasakuuri', 'baataŋaa', 'babammo', 'babaŋena')]\n"
          ]
        }
      ],
      "source": [
        "for batch_num, batch in enumerate(iterator):\n",
        "    print(batch)\n",
        "    if batch_num > 3:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2LGXQ_nMOqC"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "criterian = nn.CrossEntropyLoss(ignore_index=dagaare_to_index[PADDING_TOKEN],\n",
        "                                reduction='none')\n",
        "\n",
        "# When computing the loss, we are ignoring cases when the label is the padding token\n",
        "for params in transformer.parameters():\n",
        "    if params.dim() > 1:\n",
        "        nn.init.xavier_uniform_(params)\n",
        "\n",
        "optim = torch.optim.Adam(transformer.parameters(), lr=1e-4)\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiTPe97iMXw_"
      },
      "outputs": [],
      "source": [
        "NEG_INFTY = -1e9\n",
        "\n",
        "def create_masks(eng_batch, dg_batch):\n",
        "    num_sentences = len(eng_batch)\n",
        "    look_ahead_mask = torch.full([max_sequence_length, max_sequence_length] , True)\n",
        "    look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1)\n",
        "    encoder_padding_mask = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
        "    decoder_padding_mask_self_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
        "    decoder_padding_mask_cross_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
        "\n",
        "    for idx in range(num_sentences):\n",
        "      eng_sentence_length, dg_sentence_length = len(eng_batch[idx]), len(dg_batch[idx])\n",
        "      eng_chars_to_padding_mask = np.arange(eng_sentence_length + 1, max_sequence_length)\n",
        "      dg_chars_to_padding_mask = np.arange(dg_sentence_length + 1, max_sequence_length)\n",
        "      encoder_padding_mask[idx, :, eng_chars_to_padding_mask] = True\n",
        "      encoder_padding_mask[idx, eng_chars_to_padding_mask, :] = True\n",
        "      decoder_padding_mask_self_attention[idx, :, dg_chars_to_padding_mask] = True\n",
        "      decoder_padding_mask_self_attention[idx, dg_chars_to_padding_mask, :] = True\n",
        "      decoder_padding_mask_cross_attention[idx, :, eng_chars_to_padding_mask] = True\n",
        "      decoder_padding_mask_cross_attention[idx, dg_chars_to_padding_mask, :] = True\n",
        "\n",
        "    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n",
        "    decoder_self_attention_mask =  torch.where(look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFTY, 0)\n",
        "    decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFTY, 0)\n",
        "    return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_4RATUXMXto",
        "outputId": "e967cca5-a9b7-4cbb-b8d4-3615db76fb73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Contents of x: ('Definition', '1 and', '2 in order to', 'but', 'they', 'the', 'to hate', 'expression of surprise and regret', 'expression of regret', 'expression expressing UNKI told you soUNK', 'expression of pain', '1 expression of disapproval', '1 yes answer to a call', 'is that so expression of uncertain surprise', 'answer in agreement', 'expression of lack of confidence in someoneUNKs ability to perform a task', 'expression of total despair', 'infertile woman ', 'well then', '1 expression of despair over a repeated mishap', '1 exclamation of satisfaction or commendation', '1 palm tree 2 palm fruit', 'palm fruit', 'palm wine', 'palm oil', 'palmfrond broom', 'palm tree', 'which ones nonhuman', 'Africa', 'African')\n",
            "Contents of y: ('Word', 'a', 'a', 'a', 'a', 'a', 'a', 'aa', 'aa', 'aa', 'aae', 'a-a', 'ãa', 'ãaa', 'âaa', 'aa-ee', 'aa-hii', 'aane', 'aaŋ', 'aba', 'abaa', 'abɛ', 'abɛbiri', 'abɛdãã', 'abɛkãã', 'abɛsaare', 'abɛteɛ', 'abuobo', 'Afereka', 'Aferekaneɛ')\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Iteration 0 : 6.372082710266113\n",
            "English: Definition\n",
            "dagaare Translation: Word\n",
            "dagaare Prediction: ạ}4èèèèèèèè\\èèè-áááẽLã--ááá]èẽèèèá-!ãã<<áèá4<è<áááuããá!ã44!ãããááááá-á---ãạạạáãããạáááạããããá$$IíãèááIáãããèèãI---]-L-áá-èááá-,--ká]á]]áèuI]u8á----á---è]]]<<SH]SvSaaaácaõạɪ-I--IIãããâạãvIạạạvạ''IạạạạạvõIIIãèIããè'ââããèã-ââáãvvèLãâãèèãLèèãCèèèãIvvIIãvã-èèèèIạLãããIãIạv1ãè--ãããããèãããããããããããèããããããkèããããããá-L-ã--èkHLèèèèáãkǎããõkãèèIIèè<ὸͻ<-ͻèèèèãk=ãWͻ]\\è96666/IèkIIIkk<vèèạèãèI]6ãããèII<ã]YèLY<START>YõõIõèaaYYY66666ãYãããὸIIããããI]YIãã4Yããããã-&ã-ãããããããã}IããããH}ãããããáá-ãããI<I<ã4ãͻͻͻͻõããạ<>]õáʋãá<áͻIõõõ<õõõ<I>IIIIIIISạã/ããõãõãõõõõõõõõõõõõ]6õõõõSããã/////<LHH/ãLãõLLLL/ͻõõõõõõ/õ//õ]õ]6<6L->ã/L<LLLL--áIéI<ã-IIõõI>ͻ-õII/õõIãI-é-L<ãõõ<<õ----<vvv--$-$áááá]á<$$á]á-ã-<á<ããã<ããè1SNèãNNNNNạạãhãáãạὸ-ὸ/èạã>õõ>ãã'ạhõNáạ<áNNLạὸͻv<C>ὸὸͻ+ạạạͻạvvvvạvINạạạὸὸͻͻvõvạὸạvͻIIIὸIͻ<-ͻvèI'NI<<ạ<<--v<ͻ--ͻͻ-ͻvͻͻạͻͻIͻͻạ<IIͻạ--ͻὸͻͻͻIͻN<ééX<ƆINͻIͻèͻèèèèIèͻèè--èââèâááèY-v-CããããIãããããããvèͻãããã-ạãããããC---õããããããããããããNvãYv<CãǎI]]]LkèCC\\ããǎIʊõLLLõõõNN8kǎ\\KvvL<vvạvv<vὸὸ\\vvvvvèvLèạ}èạvCὸὸèèvvvCvvvãvYvvããY!LXãLèèèèNYLNY<N<NNvXN]X<ὸὸὸNvè>XXὸèvὸè\n",
            "Contents of x: ('should we go to the mall?',)\n",
            "Contents of y: ('',)\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('should we go to the mall?',)\n",
            "Contents of y: ('a',)\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('should we go to the mall?',)\n",
            "Contents of y: ('aa',)\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('should we go to the mall?',)\n",
            "Contents of y: ('aaa',)\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('should we go to the mall?',)\n",
            "Contents of y: ('aaaa',)\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('should we go to the mall?',)\n",
            "Contents of y: ('aaaaa',)\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('should we go to the mall?',)\n",
            "Contents of y: ('aaaaaa',)\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('should we go to the mall?',)\n",
            "Contents of y: ('aaaaaaa',)\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('should we go to the mall?',)\n",
            "Contents of y: ('aaaaaaaa',)\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('should we go to the mall?',)\n",
            "Contents of y: ('aaaaaaaaa',)\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('should we go to the mall?',)\n",
            "Contents of y: ('aaaaaaaaaa',)\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('should we go to the mall?',)\n",
            "Contents of y: ('aaaaaaaaaaa',)\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('should we go to the mall?',)\n",
            "Contents of y: ('aaaaaaaaaaaa',)\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('should we go to the mall?',)\n",
            "Contents of y: ('aaaaaaaaaaaaa',)\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('should we go to the mall?',)\n",
            "Contents of y: ('aaaaaaaaaaaaaè',)\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('should we go to the mall?',)\n",
            "Contents of y: ('aaaaaaaaaaaaaèè',)\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('should we go to the mall?',)\n",
            "Contents of y: ('aaaaaaaaaaaaaèèa',)\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('should we go to the mall?',)\n",
            "Contents of y: ('aaaaaaaaaaaaaèèaa',)\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('should we go to the mall?',)\n",
            "Contents of y: ('aaaaaaaaaaaaaèèaaa',)\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('should we go to the mall?',)\n",
            "Contents of y: ('aaaaaaaaaaaaaèèaaaa',)\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('should we go to the mall?',)\n",
            "Contents of y: ('aaaaaaaaaaaaaèèaaaaa',)\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('should we go to the mall?',)\n",
            "Contents of y: ('aaaaaaaaaaaaaèèaaaaaa',)\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('should we go to the mall?',)\n",
            "Contents of y: ('aaaaaaaaaaaaaèèaaaaaaa',)\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Evaluation translation (should we go to the mall?) : ('aaaaaaaaaaaaaèèaaaaaaa<END>',)\n",
            "-------------------------------------------\n",
            "Contents of x: ('preface of a book', '1 to dance 2 to jump up and down', '1 to fly 2 erect', 'to ask for permission to join someone knock door', 'a type of silky', 'bad luck', 'thatUNKs right expression of agreement', 'an expression that denotes UNKwellUNK', 'no', 'an expression of despair', 'expression of boastful challenge', 'expression of disappointment at failure', 'expression of disgust and disagreement', 'expression of despair', 'The thieves have robbed my friend again', 'emphatic form of aku', 'expression indicating oneUNKs inability to do a task', 'God', 'I swear', 'in the name of God', 'to open ring', 'expression ordering one to get out away with you', 'metaphor literature', 'expression of surprise mixed with fear', 'hello', 'aeroplane', 'airport', 'but', 'these 3rd person plural demonstrative nonhuman', 'a type of small tree with large leaves and pink fruit')\n",
            "Contents of y: ('afu', 'age', 'age', 'agoo', 'agoo', 'agye', 'ahâa', 'ahaŋ', 'ai', 'aii', 'akaase', 'akaasemanakei', 'akaase akai', 'aku', 'akuroku', 'akuroku', 'akuu', 'Ala', 'ala', 'alaakosebaroo', 'ale', 'alee', 'aleɛma', 'alɛ', 'aloo', 'aloopelee', 'aloopeleeduoraa', 'ama', 'ama', 'ambaŋenaa')\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('America', '1 perhaps', 'much more than exaggeration', 'thanks', 'those 3rd person plural strong form nonhuman', 'four', 'because', 'reason', 'those ones 3rd person plural demonstrative', 'it a problem', '1 world 2 people of the world', '1 and 2 although', 'despite', 'effort', 'welcome an expression of goodwill to a stranger who has just arrived', 'gratitude', 'eight', '1 a traditional womenUNKs dance 2 music for such a dance', 'who which person interrogative pronoun', 'before', '1 a type of edible berry that turns violet when ripe 2 the tree of this fruit', 'a woman who has recently given birth', 'noon used as a greeting', 'five', 'one who is great or strong physically or spiritually', 'to be alerted used to caution or persuade', 'who interrogative pronoun', 'no one retort implies the matter is none of the askerUNKs business', 'like', 'having the blades burnt away')\n",
            "Contents of y: ('Ameleka', 'aminekaŋa', 'amma', 'ammeseɛrɛ', 'ana', 'anaare', 'ananso', 'ananso', 'anaŋ', 'anaŋ', 'andonɛɛ', 'ane', 'aneazaa', 'aneɛ', 'anesɛ', 'angyoɔso', 'anii', 'anlee', 'annoo', 'ansaŋ', 'ansiŋinee', 'ansoɔnee', 'antere', 'anuu', 'anwoŋ', 'aŋ', 'aŋ', 'aŋa', 'aŋa', 'aŋgaara')\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('a type of long grass used to weave sleeping mats', 'to adorn', 'Accra', 'river blindness', 'barrel', 'of course expression of certainty', 'expression of unpleasant surprise', 'emphatic expression of despair', 'to gather up oneUNKs courage', 'kidney', 'to cut', 'to be related through the motherUNKs line', '1 to stand 2 to wait UNK N baUNK ka o na are la ka N gaa te pUNKge o I know she will wait so that I go to meet himher 3 to stop UNK A wUNKUNKkye kyUNKUNKUNKUNK la tasoga tasoga leUNK are The watch worked for a while and then stopped', 'to tear off from the main body branch or limb of an animal', 'maternal uncle', 'eldest niece', 'nephew or niece', 'arithmetic', '1 standing place', '1 standing place position 2', 'not negative particle', '1 they', 'to fix a pointed object firmly in the ground', 'to gallop', '1 father 2 friend between males 3 Mister', 'or normally used in question tag', 'dog', 'a small black ground antlike creature which burrows into the ground with the tip of its abdomen', 'a type of childrenUNKs game', 'body of water')\n",
            "Contents of y: ('aŋgeli', 'aŋgoɔle', 'Aŋkara', 'aŋko', 'aŋkorɔ', 'ão', 'apa', 'aparapa', 'ara', 'arambiri', 'are', 'are', 'are', 'are', 'areba', 'arekpoŋ', 'arelee', 'aremateke', 'arezie', 'aroozie', 'ba', 'ba', 'ba', 'ba', 'ba', 'baa', 'baa', 'baa', 'baa', 'baa')\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('1 to grow up', 'father familiar term of address used by toddlers', 'Bible', 'bustard', 'goodbye', 'bag', 'patient', '1 slim', 'to ache slightly disconfort of the stomach UNK Ka maaUNK iri ba gaa bangyeraa n poUNK maUNK baala la If I donUNKt go to the toilet for the day I normally have a slight stomachache baalUNKUNK', 'to separate grains from unwanted material UNK A pUNKge baale iri la a seUNKkUNKabie yi a pUNKgere poUNK The woman separated the groundnuts from the shells baalUNKUNK', 'hospital', 'the act of supporting someone by holding them by the midsection UNK Ba kpUNK la a baala baalimbo gaa ne a asibiti They supported the patient by the midsection and took him to the hospital', 'germ', 'feast organised for a friend UNK Te daare gaa la baalomboUNKlaa Loraa poUNK We attended a friendship feast in Lawra', 'contagious disease', 'recurring illness', 'friendship UNK Ba nyUNKge la baaloUNK saUNKa zaa They have been friends for a long time', 'illness', '1 calm UNK ZenUNK', '1 gallon measure 2 balloon', 'Ursa Major constellation also known as Big Dipper', 'lily pads pl sg baapUNKmpUNKloo pl baapUNKmpUNKlUNK 2pl baapUNKmpUNKUNKbaapUNKmpUNKllUNKUNK', 'end', '1 to finish', '1 a seed from a type of tree 2 a type of large bead made from this seed', 'Baasare ethnic group', 'bicycle', 'a type of tree that resembles the shea nut tree', 'ignorance', 'one who is innocent')\n",
            "Contents of y: ('baa', 'baabaa', 'Baabol', 'bãabõo', 'baaebaae', 'baage', 'baala', 'baalaa', 'baale', 'baale', 'baalebayiri', 'baalimbo', 'baalombiri', 'baalomboɔlaa', 'baalonlɔnnaa', 'baalonnooraa', 'baaloŋ', 'baaloŋ', 'baaloŋ', 'baaluu', 'baa-ne-ŋmaaŋa', 'baapɛmpɛle', 'baaraa', 'baare', 'baasaabiri', 'Baasaale', 'baasakuuri', 'baataŋaa', 'babammo', 'babaŋena')\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('innocence', 'broth from dog meat', 'a friend that cannot be trusted', 'bridge', 'the breast of a dog', 'dog faeces', 'a type of tree', 'bosom friend', 'the deepest part of a body of water', 'spring', 'male dog', 'the last day of a festival', 'uncastrated male dog', 'male puppy', 'castrated dog', '1 spider 2 cunning person', 'the deepest part of a body of water', 'a plant with a sweet smell', 'female dog that has recently given birth', '1 valley 2 creek', 'a triangular garment worn by men as underwear', 'not caring', 'dog leash', 'dog skin', 'mad dog', 'a type of sacred cult which initiates boys and girls into adulthood', 'the act of divining', 'divining stick', 'divining bag', 'sacrifice for gods')\n",
            "Contents of y: ('babaŋyeli', 'babẽe', 'babeɛ', 'babeɛraa', 'babere', 'babini', 'babiŋ', 'babiri', 'babogi', 'babullaa', 'badaa', 'badaa-de-nyoɔre', 'badalane', 'badalee', 'badavaraa', 'badɛre', 'badie', 'badoge', 'badɔgerɔ', 'bafoɔlaa', 'baga', 'baga', 'baganaa', 'bagane', 'bagao', 'bageba', 'bageboge', 'bageboge-dagoli', 'bageboge-woɔ', 'bagere')\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('very early morning usually cold', 'morning', 'early morning', 'very early morning', 'leg of a dog', 'valley', 'fool', 'trough for a dog', 'a type of childrenUNKs dance', '1 squirrellike rodent believed to be very sexually active 2 sex maniac male', 'a thick', 'a type of wild mouse found along river valleys which has tender skin', 'broth from dog meat', 'trusted friend', 'a type of yam early maturing', '1 large stream', 'waistband pair of shorts', 'peg used for tethering animals', 'peg used for tethering animals', 'large and heavy', 'belt', '1 to be tired 2 to be fed up 3 to be weak 4 to be soft', 'tribe', '1 avoid', 'of a kind', 'brook', 'puppy', 'of a dubious and dangerous nature', 'tick', '1 ugly person or thing 2 one without strength')\n",
            "Contents of y: ('bagukyɔfeɛle', 'baguo', 'bagupi', 'bagupipi', 'bagbɛre', 'bagbɛre', 'bagboŋ', 'bagbori', 'bagyeɛnɛ', 'bagyoɔ', 'bagyɔroo', 'ba-irime', 'bakana', 'bakore', 'bakɔ', 'bakpoŋ', 'balaa', 'balambaaraa', 'balambiri', 'balantamm', 'balante', 'bale', 'bale', 'bale', 'bale', 'balee', 'balee', 'balee', 'baleŋkpɔgre', 'balɔre')\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('1 not being strong 2 act of being ugly', 'a type of large yam', 'these 3rd person plural demonstrative human', 'unassuming person poor person', 'small fish', 'swallow bird', 'hot', 'an arrangement made in advance by two parties', 'confused person fool', 'salp fish of the class Thaliacea', 'locally made gunpowder', 'big and heavy', 'intelligence', 'a type of tall', 'lizard male', 'the act of hitting the opponentUNKs armpits with oneUNKs knees to weaken the opponent a wrestling move', 'Agama agama lizard also known as redheaded rock agama', 'large male lizard', 'tooth of a lizard', 'female lizard', 'kite small bird of prey', 'tail of a lizard', 'a bangle that is believed to have medicinal value and may be worn to cure a disease', 'bank', 'latrine washroom feces', 'a dog', 'a type of spotted lizard believed to be poisonous', 'rectal bulb syringe', 'carnivorous bird bigger than a kite but strong and fast', 'copper bangle')\n",
            "Contents of y: ('balɔrroŋ', 'bam', 'bama', 'bambaala', 'bambaalaa', 'bambaalaaraa', 'bambaŋ', 'bambiŋi', 'bambugo', 'bambuŋi', 'bambuŋi', 'bamm', 'bammo', 'bamoɔ', 'bandaa', 'bandaakpogilo', 'bandakarekpele', 'bandakarema', 'bandanyene', 'bandapoleɛne', 'bandazeɛraa', 'bandazoore', 'banfane', 'bangye', 'bangyeraa', 'ba-nimie-anaare', 'bantakperee', 'bantoɔ', 'banweebaa', 'banzeɛ')\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('bird that eats lizards', 'chain', 'chest of a dog', 'intestine of a dog', 'female dog', 'homeland of the BanyenUNKUNK clan', 'name of a clan', 'imitation', 'bangle', 'lizard', 'to know something or someone to be aware of', 'area between the shoulder and neck trickster', 'a type of tree that has medicinal properties', 'cleverness', 'highheeled shoes', 'a type of brown bird with long', 'foreknowledge', 'twisted bangle', 'a dogUNKs nest', 'close friend', 'end of a valley', 'a puppy earmarked for someone', 'a small part of the stomach of a ruminant that has many compartments', 'boastful threat', 'not making any effort helpless', 'to leave', 'to cultivate seeds to offer firstfruits to the gods', 'local spirits alcohol', 'to haggle', 'lazy and useless dog')\n",
            "Contents of y: ('banzeɛraa', 'banzɔlɔ', 'banyaa', 'banyagere', 'banyaŋaa', 'Banyene', 'Banyenɛɛ', 'banyɛtɔgle', 'baŋa', 'baŋa', 'baŋe', 'baŋena', 'baŋenaa', 'baŋene', 'baŋgori', 'baŋkaroŋ', 'baŋkoroŋ', 'baŋŋmeɛle', 'ba-ɔge', 'bapare', 'bapare', 'bapiiraa', 'bapimbaare', 'bara', 'baraa', 'bare', 'bare', 'barekanneɛbaa', 'barre', 'ba-sakɔre')\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('slippery waterway', 'weak and sickly dog', 'the state of not having anything', 'poor or needy person', 'bosom friend', 'lake', 'a type of dance', 'people of Bayaayiri', 'a settlement in the Upper West Region ancestorsUNK dwelling next world', 'name traditionally given to a male child born on a funeral day', 'blood of a dog', 'tongue of a dog', 'a type of wild fox', 'fast dog', 'a type of wild mouse that has thick fur', 'to exist', 'there place', 'to become boiled or cooked to be smooth flour to mature', 'or', 'present', 'termite hill', 'white ant', 'a pessimist', 'one who is malicious', 'malicious talk', 'the act of causing trouble', 'last day', 'particular day', 'first day', 'sabbath sacred day')\n",
            "Contents of y: ('basasale', 'ba-soɔmee', 'bataabo', 'batara', 'batuo', 'bavilime', 'bawaa', 'Bayaayiree', 'Bayaayiri', 'Bayuo', 'bazẽe', 'bazele', 'bazoɔ', 'bazoraa', 'bazugiri', 'be', 'be', 'be', 'be', 'bebe', 'bebelaa', 'bebelebiri', 'beberaa', 'beberee', 'beberiyɛlɛ', 'beberuŋ', 'bebibaaraa', 'bebibalaa', 'bebidɛŋe', 'bebifaa')\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('whole day', 'a former day', 'new day different day', 'date', 'strange day', 'good day', 'distant date', 'free day', 'one day', 'to exist to be present', 'or', 'concentrated extraction from something tasty', 'to envy with evil intent', 'to move slightly away from a spot', 'strong person one with supernatural power', 'wellcooked', 'to move majestically to roam round leisurely', 'to kill', 'to move out of the way allowing another to pass to divert to pass someone by', 'to slice meat', 'funny strange', 'beer', 'strange', 'small', 'to accompany', 'to cut in strips meat', 'slowly bit by bit', 'multitude', 'older brother', 'to follow up')\n",
            "Contents of y: ('bebigbuli', 'bebikore', 'bebipaalaa', 'bebiri', 'bebisaana', 'bebisoŋ', 'bebitɔɔre', 'bebivuo', 'bebiyeni', 'bee', 'bee', 'bẽe', 'beele', 'beele', 'beene', 'beene', 'beene', 'beere', 'beɛ', 'beɛ', 'beɛ', 'bẽɛ', 'beɛbeɛ', 'beɛlaa', 'beɛle', 'beɛle', 'beɛlɛbeɛlɛ', 'bẽɛo', 'beɛre', 'beɛre')\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('to cut into strips', 'to stop up', 'law', 'lawmaker member of parliament', 'parliament house', 'wing', 'anthill', 'what interrogative pronoun', 'small quantity', 'to do extraneous work', 'yeast', 'big and fat person', 'that place', 'to intrude', 'intruder especially to meals', 'a type of wild mouse that has thick fur', 'to exist', 'there place', 'to become boiled or cooked', 'or', 'present', 'termite hill', 'white ant', 'a pessimist', 'one who is malicious', 'malicious talk', 'the act of causing trouble', 'last day', 'particular day', 'first day')\n",
            "Contents of y: ('beɛre', 'bege', 'bege', 'begebinne', 'begebiŋi-duoraa', 'begere', 'belaa', 'belaa', 'belaa', 'bele', 'bele', 'belefele', 'benee', 'benne', 'bennɛ', 'bazugiri', 'be', 'be', 'be', 'be', 'bebe', 'bebelaa', 'bebelebiri', 'beberaa', 'beberee', 'beberiyɛlɛ', 'beberuŋ', 'bebibaaraa', 'bebibalaa', 'bebidɛŋe')\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('sabbath sacred day', 'whole day', 'a former day', 'new day different day', 'one day', 'to exist to be present', 'or', 'concentrated extraction from something tasty', 'to envy with evil intent', 'strong person one with supernatural power', 'wellcooked', 'to move majestically to roam round leisurely', 'to kill', 'to move out of the way allowing another to pass to divert to pass someone by', 'to slice meat', 'funny strange', 'beer', 'strange', 'small', 'to accompany', 'to cut in strips meat', 'to move slightly away from a spot', 'to intrude', 'the state of being supernaturally powerful', 'to be sick', 'to seal', 'where interrogative pronoun', 'mud', 'where interrogative pronoun', 'sheep')\n",
            "Contents of y: ('bebifaa', 'bebigbuli', 'bebikore', 'bebipaalaa', 'bebiyeni', 'bee', 'bee', 'bẽe', 'beele', 'beene', 'beene', 'beene', 'beere', 'beɛ', 'beɛ', 'beɛ', 'bẽɛ', 'beɛbeɛ', 'beɛlaa', 'beele', 'beele', 'beele', 'beene', 'berroŋ', 'bɛ', 'bɛ', 'bɛ', 'bɛbɛgere', 'bɛɛ', 'bɛɛ')\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('hemp seeds', 'to embank to block with a dam', 'a shell of a particular type of seed', 'nightengale', 'belt', 'to deceive', 'to coax a baby', 'to look at closely', 'bean flour shaped into slabs and steamed', 'extremely black', 'to move in a shaky manner', 'bean seed', 'barn for storing beans', 'bean sprout', 'new', 'white beans', 'unripened bean seed', 'bean husk', 'bean stalk', 'a cooked bean dish usually not seasoned', 'the fruit of a bean plant', 'bean flour', 'tender seedless fruit of a bean plant', 'to sift', 'to pretend to invite someone to share something but not wholeheartedly', 'beans', 'a variety of beans', 'old beans', 'dry bean', 'trap')\n",
            "Contents of y: ('bɛɛne', 'bɛge', 'bɛgelaa', 'bɛlɛmbɛgere', 'bɛlɛnte', 'bɛlle', 'bɛlle', 'bɛlle', 'bɛllebɛllɛ', 'bɛmbɛŋ', 'bɛmbɛŋ', 'bɛmbiri', 'bɛmbugo', 'bɛmbuli', 'bɛmpaala', 'bɛmpelaa', 'bɛmpɛɛre', 'bɛmpɛge', 'bɛndaa', 'bɛndaa', 'bɛnwɔne', 'bɛnzɔŋe', 'bɛnzɔɔre', 'bɛŋe', 'bɛŋe', 'bɛŋɛ', 'bɛŋgbɛre', 'bɛŋkorɔ', 'bɛŋkuoŋaa', 'bɛraa')\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('razor', 'to set a trap to poison to ponder', 'to exclude', 'pollen from the kenaf plant which causes itching', 'fat', 'small child', 'toy', 'young child', 'the act of playing chess', 'firstborn human', 'firstborn human', 'sibling clan level', 'son', 'child', 'day', 'a type of game played using marbles', 'tomorrow', 'to come to pass', 'daily every day', 'tomorrow', 'stinginess', 'bad child', 'bad pebble', 'small quantity of pebbles', 'light pebble', 'any bedding for a child', 'postnatal care', 'leather spread for a baby cot', 'all over area', 'big heavy sound fall of a big wall')\n",
            "Contents of y: ('bɛraa', 'bɛre', 'bɛre', 'bɛren-uri', 'bɛroŋ', 'bibile', 'bibile-deɛnaa', 'bibilpɔɔ', 'bibore', 'bidɛndɛŋe', 'bidɛŋe', 'bidɔŋe', 'bidɔɔ', 'bie', 'bie', 'bie', 'bie', 'bie', 'biebie', 'bieo', 'bieri', 'bifaa', 'bifaa', 'bifẽe', 'bifõɔo', 'bigaalaa', 'bigaale', 'bigane', 'bigeŋ', 'bigeŋ')\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('large and heavy', 'fibre kenaf a plant that produces fibre', 'fibrelike', 'to describe', 'sand', 'desert', 'desert', 'the act of caring for children', 'the act of gathering pebbles', 'caretaker of a child', 'the act of killing children', 'a child that cries a lot', 'industrious person', 'old chap', 'baby cot', 'dead child', 'orphan', 'smart child', 'toddler', 'firstborn nonhuman', 'small', 'offspring nonhuman', 'young baby', 'round and smooth', 'caterpillar track', 'large and heavy', 'bloated and large', 'baby newly born', 'grabbing on to a huge object by throwing both arms around it', 'roll a heavy object along the ground')\n",
            "Contents of y: ('bigileŋ', 'bigiri', 'bigiri', 'bigiri', 'biiree', 'biiridalempoɔ', 'biirikpoŋi', 'bikaa', 'bikaale', 'bikaara', 'biko', 'bikoŋkonaa', 'bikoɔraa', 'bikore', 'bikũu', 'bikũu', 'bikpeebɛ', 'bikyelaa', 'bikyɛnaa', 'bildɛŋe', 'bile', 'bile', 'bileɛ', 'bilembileŋ', 'bilembileŋ', 'bilembileŋ', 'bilentimm', 'bilɛɛ', 'bilibala', 'billi')\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('roll between the palms to mould', 'baby sling', 'extremely dark rain clouds', 'pen', 'good child', 'large and solid', 'white faeces fear', 'flatulence', 'cloth used for cleaning faeces of a baby', 'excrement', 'open place full of defecation', 'act of misbehavior', 'beloved child favorite', 'the act of loving children the act of pampering', 'a type of diarrhoea', 'dysentery', 'to put down to place to set out to store up', 'to shift unsteadily', 'watery faeces', 'one suffering from diarrhoea', 'baby cot', 'pampered child', 'a lad young man', 'young man', 'young man', 'young woman', 'one who stammers', 'cause debris to drop down from a height', 'to stutter', 'to pass by narrowly')\n",
            "Contents of y: ('billi', 'bimaraa', 'bimbiŋ', 'bimbiŋe', 'bimeŋɛ', 'bimm', 'bimpeɛle', 'bimporɔ', 'bin-eɛraa', 'bini', 'binkyoo', 'binnyeɛbo', 'binɔnaa', 'binɔŋe', 'bintanyeɛrɛ', 'binzẽe', 'biŋi', 'biŋibiŋi', 'biŋkõɔ', 'biŋkɔnnyeɛrɛ', 'bipeɛ', 'bipoɔnaa', 'bipɔlbile', 'bipɔlee', 'bipɔllee', 'bipuulee', 'biraa', 'biri', 'biri', 'biri')\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('chaff from malt', 'seed', 'something of worth', 'rushing in large numbers eg in a stampede', 'completely', 'to slip', 'brake brick', 'mould for bricks', 'brake pad', 'brick', 'wild ducklike water bird', 'very large duck', 'duck', 'father human', 'good child', 'virgin', 'midwife', 'baby adopter', 'strayed or wayward child', 'spoilt child', 'problem child beloved child', 'babysitter', 'the act of babysitting', 'welltravelled person one who roams a lot', 'naming ceremony baby', 'popular person', 'young baby', 'young baby', 'to gather momentum rain seen coming from afar in full scale', 'to confer')\n",
            "Contents of y: ('biri', 'biri', 'biri', 'biribiri', 'biribiri', 'biribiri', 'birikyi', 'birikyilaa', 'birikyisaabo', 'birisi', 'biriyokpekperaa', 'biriyonaameɛo', 'biriyuo', 'bisaa', 'bisoŋ', 'bitoroo', 'bitɔgelɔ', 'bituuro', 'biweɛmɛ', 'biweɛraa', 'biwolaa', 'biyaalaa', 'biyaale', 'biyoɔraa', 'biyopore', 'biyuori', 'bizɛgɛ', 'bizɔnzɔɔ', 'bo', 'bo')\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('a type of carnivorous bird', 'extremely voluminous', 'a type of termite', 'huge carnivorous bird', 'male goat', 'a type of tree with edible fruit', 'a type of tree with edible fruit', 'wild tigernut not edible', 'male goat uncastrated', 'young male goat', 'male goat with long hair on the chin bearded male goat', 'castrated male goat', 'to break into little bits or pulp', 'hole grave pit ditch limit', 'subway', 'a type of rodent not edible', 'round', 'bucket', 'the act of burying a human corpse', 'xylophone music signaling the completion of the burial of the dead', 'fee for those who bury the dead', 'chief undertaker one who buries the dead', 'one who buries the dead', 'ritual TZ for those who bury the dead', 'ritual dish for those who bury the dead', 'amateur undertaker', 'uncovered tomb', 'grave', 'ground into pulp', 'goats given to one to raise in return for some')\n",
            "Contents of y: ('bobɛllɛ', 'boboo', 'boboruu', 'bobɔge', 'bodaa', 'bodaa-ansiinee', 'bodaanonnoonaa', 'bodaasensɔɔre', 'bodalane', 'bodalee', 'bodateɛne', 'bodavaraa', 'bogere', 'bogi', 'bogigbɛre-katakye', 'bogikantoo', 'bogisulee', 'bogiti', 'bogi-ũu', 'bogi-ũu-faare', 'bogi-ũu-libie', 'bogi-ũu-naazoɔ', 'bogi-ũuno', 'bogi-ũu-saabo', 'bogi-ũu-sawɔlɔ', 'bogi-ũu-zanna', 'bogivuo', 'bogizeɛ', 'bogɔbogɔ', 'boguolo')\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('one who buries the dead undertaker', 'tasteless powdered stuff', 'a daily marketplace', 'lean or thin goat', 'old goat', 'to sympathise with', 'talking continuously', 'to burst strongly', 'to smear all over', 'to speak unintelligibly', 'kid young goat', 'tethered goat one restricted from moving', 'the act of tethering goats', 'to be foolish', 'not adulterated', 'to murmur to talk inaudibly', 'a type of vegetable', 'lukewarm water', 'what interrogative pronoun', 'a sick thing', 'a slim or narrow thing', 'something that can grow', 'the last one', 'something which is avoided', 'kind of thing referring to something huge or strange', 'things of all sorts', 'something which is known', 'the act of knowing knowledge', 'the act of releasing the act of offering firstfruits to gods', 'something that is cooked or ripe')\n",
            "Contents of y: ('bog-uuno', 'bokolɔ', 'bokontawɛ', 'bokoŋ', 'bokore', 'bokpɛ', 'bolaakaatoo', 'bolaare', 'bole', 'bolebole', 'bolee', 'bolenaa', 'bo-leŋi', 'boli', 'boli', 'bolle', 'bolɔ', 'bolɔbolɔ', 'boluu', 'bombala', 'bombaalaa', 'bombaaraa', 'bombaaraa', 'bombalaa', 'bombalaa', 'bombaltakyelmɛ', 'bombannaa', 'bombaŋe', 'bombare', 'bombeene')\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('something strange or mysterious', 'sliced strips of leather that which is patched or to be patched as in car tyre', 'boils', 'very young ones unhatched embryos in eggs', 'young donkey foal', 'small thing', 'seed cereal', 'a small plant with a jellylike tuber the tuber or flour made from the tuber of this plant fried dish made from the flour of this plant', 'a thing that is not of the same species a strange thing', 'a useless thing', 'a type of tree', 'something that cannot be classified', 'something that is kept for posterity seed for sowing', 'seed for planting', 'something that is sought something that is wanted or liked', 'things one wishes to have wealth', 'something that is sown a crop', 'the act of sowing', 'fried duff from bombo flour', 'quest for wealth', 'the act of grinding into fine pulp', 'the forearm or leg of an animal', 'something that is nursed', 'something that can sprout from a seed', 'shoot of a new plant', 'a measure something that is respected', 'something that is made', 'the act of making', 'an egg that is immature something that is tiny', 'a wet')\n",
            "Contents of y: ('bombeɛ', 'bombeɛraa', 'bombeɛre', 'bombiiri', 'bombile', 'bombile', 'bombiri', 'bombo', 'bombolaa', 'bombone', 'bombonoone', 'bomboŋɔ', 'bombooree', 'bomboorɔ', 'bomboɔraa', 'bomboɔre', 'bomboraa', 'bombore', 'bombo sawɔlɔ', 'bombɔ', 'bombɔge', 'bombɔgɔ', 'bombugilaa', 'bombulaa', 'bombuli', 'bombuuraa', 'bommaalaa', 'bommaale', 'bommaane', 'bommaaroŋ')\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('a measure something that is measured', 'new or fresh things firstfruits of crops', 'the vulva of any animal', 'the vulva of a donkey', 'foot rot', 'residue bottom', 'a very young animal', 'a piece torn from a piece of cloth', 'the act of decorating', 'something that is moving and must be intercepted', 'something that is adorned', 'a piece of a broken container calabash', 'a white thing', 'the act of dehusking removing the dry outer cover of a grain', 'the act of scratching as by fowl', 'an immature thing', 'the act of washing the shell or bark of something', 'something that is carried by holding it to oneUNKs side', 'something that has been washed something for washing', 'something that can be peeled', 'the act of peeling', 'peel', 'something that is carved', 'the process of becoming distended or bloated claims in advance for something', 'something that is to be watched or ought to be watched', 'a lost thing that is found an unexpected find an easy find', 'a distended thing', 'something that has been earmarked for someone', 'one who finds a lost item', 'something on which an oath is taken')\n",
            "Contents of y: ('bommannaa', 'bompaala', 'bompaare', 'bompaare', 'bompaare', 'bompare', 'bompeelaa', 'bompeelaa', 'bompege', 'bompegelaa', 'bompegeraa', 'bompegɛ', 'bompelaa', 'bompere', 'bompere', 'bompɛɛre', 'bompɛge', 'bompɛgelaa', 'bompɛgeraa', 'bompɛlaa', 'bompɛle', 'bompɛle', 'bompɛnnaa', 'bompi', 'bompigiraa', 'bompiiraa', 'bompiiraa', 'bompiiraa', 'bompiire', 'bompollaa')\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('a pregnant thing nonhuman', 'something by which one swears', 'something that is poured', 'a situation of plentiful things', 'something that is small and short a little thing', 'the act of pouring', 'the act of swearing or taking an oath on something', 'a female thing', 'the act of confining animals in enclosures', 'something that is confined in an enclosure', 'a young thing', 'the act of plucking something fruits or groundnuts', 'harvester', 'an ashcoloured thing', 'various things mixed up', 'something that has flowered', 'something that is or can be praised', 'flowers of things', 'four times', 'winged creature insect', 'the act of buying', 'male donkey', 'a male thing', 'the act of pushing', 'rich person one who has wealth', 'something that is bought something that is meant for sale', 'carefree', 'the act of taking', 'a dwarflike thing', 'example')\n",
            "Contents of y: ('bompoɔ', 'bompoɔraa', 'bomporaa', 'bompore', 'bompore', 'bompore', 'bompɔ', 'bompɔge', 'bompɔge', 'bompɔgeraa', 'bompɔle', 'bompɔre', 'bompɔrɔ', 'bompugo', 'bompulonpuloŋ', 'bompuuraa', 'bompuuraa', 'bompuuri', 'bonaare', 'bon-agraa', 'bonda', 'bondaa', 'bondaa', 'bondaa', 'bondaana', 'bondaaraa', 'bondaga', 'bonde', 'bondegere', 'bondemannewullaa')\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('a dirty thing', 'the act of eating', 'delicious and assorted food luncheon', 'raw food food that is not well cooked', 'leftover food', 'cook one who prepares food', 'food something that is edible a sharp thing blade', 'one who eats rightful owner', 'food things to eat', 'the act of wasting food', 'restaurant', 'something that is used for cooking', 'a boiled thing', 'something that bites insect', 'heap', 'an extra thing', 'hat which has been born', 'an animal that has recently littered', 'thing', 'worthless or useless', 'container', 'the act of robbing robbery', 'a bad or evil thing', 'robber thief', 'something that is robbed', 'a rough thing', 'a rough', 'a small quantity', 'small and tight opening', 'narrow space')\n",
            "Contents of y: ('bondɛgere', 'bondi', 'bondikaama', 'bondikaraa', 'bondi-kpaa', 'bondimaala', 'bondiraa', 'bondire', 'bondirii', 'bondi-sãa', 'bondizie', 'bondogelaa', 'bondogeraa', 'bondonaa', 'bondori', 'bondɔgelaa', 'bondɔgeraa', 'bondɔgerɔ', 'bone', 'bone', 'bon-ennaa', 'bonfa', 'bonfaa', 'bonfaara', 'bonfaaraa', 'bonfane', 'bonfarafara', 'bonfẽe', 'bonfeeloo', 'bonfegɛ')\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n",
            "Contents of x: ('a narrow thing', 'seedless pod', 'an immature thing', 'powerful spiritual beings', 'a light thing', 'a narrow thing', 'something that is used to plug an opening', 'something that is cool something that threatens', 'eight times', 'gift', 'a torn thing', 'something that is contributed something that is cut', 'a half thing', 'a worthless thing', 'uncastrated animal', 'a small thing', 'colt', 'the act of rolling over and over', 'scarcity', 'v', 'the act of trampling on things the act of ironing clothes', 'to burn pain to burn with fire', 'something that is very valuable', 'a sweet thing', 'chest of most important part of', 'a clever or wise animal', 'coarseness flour', 'intestines of nonhuman creatures', 'female', 'female donkey')\n",
            "Contents of y: ('bonfogeloo', 'bonfogiluu', 'bonfole', 'bonfolo', 'bonfõɔo', 'bonfɔraa', 'bonfuraa', 'bonfuuraa', 'bonii', 'bonkyaaraa', 'bonkyẽɛ̃', 'bonkyeɛraa', 'bonkyɛlee', 'bonlaane', 'bonlane', 'bonlee', 'bonlee', 'bonnaakale', 'bonnaŋ', 'bonne', 'bonneɛ', 'bonni', 'bonnimiri', 'bonnoɔ', 'bonnyaa', 'bonnyaanaa', 'bonnyaara', 'bonnyagere', 'bonnyaŋaa', 'bonnyaŋaa')\n",
            "Type of x: <class 'tuple'>\n",
            "Type of y: <class 'tuple'>\n"
          ]
        },
        {
          "ename": "KeyError",
          "evalue": "'̃'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-1960d8004f94>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mencoder_self_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_self_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_cross_attention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meng_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdg_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         dg_predictions = transformer(eng_batch,\n\u001b[0m\u001b[1;32m     15\u001b[0m                                      \u001b[0mdg_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                                      \u001b[0mencoder_self_attention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/dagaare_words_definition/Transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y, encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask, enc_start_token, enc_end_token, dec_start_token, dec_end_token)\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_self_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menc_start_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menc_end_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         out = self.decoder(x, \n\u001b[0m\u001b[1;32m    311\u001b[0m                            \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                            \u001b[0mdecoder_self_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/dagaare_words_definition/Transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y, self_attention_mask, cross_attention_mask, start_token, end_token)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_attention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/dagaare_words_definition/Transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, start_token, end_token)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/dagaare_words_definition/Transformer.py\u001b[0m in \u001b[0;36mbatch_tokenize\u001b[0;34m(self, batch, start_token, end_token)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mtokenized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msentence_num\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m            \u001b[0mtokenized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msentence_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Directly stack the tokenized sentences into a tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/dagaare_words_definition/Transformer.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(sentence, start_token, end_token)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0msentence_word_indicies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstart_token\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0msentence_word_indicies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTART_TOKEN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/dagaare_words_definition/Transformer.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0msentence_word_indicies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstart_token\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0msentence_word_indicies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTART_TOKEN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '̃'"
          ]
        }
      ],
      "source": [
        "transformer.train()\n",
        "transformer.to(device)\n",
        "total_loss = 0\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch}\")\n",
        "    iterator = iter(train_loader)\n",
        "    for batch_num, batch in enumerate(iterator):\n",
        "        transformer.train()\n",
        "        eng_batch, dg_batch = batch\n",
        "        encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(eng_batch, dg_batch)\n",
        "        optim.zero_grad()\n",
        "        dg_predictions = transformer(eng_batch,\n",
        "                                     dg_batch,\n",
        "                                     encoder_self_attention_mask.to(device),\n",
        "                                     decoder_self_attention_mask.to(device),\n",
        "                                     decoder_cross_attention_mask.to(device),\n",
        "                                     enc_start_token=False,\n",
        "                                     enc_end_token=False,\n",
        "                                     dec_start_token=True,\n",
        "                                     dec_end_token=True)\n",
        "        labels = transformer.decoder.sentence_embedding.batch_tokenize(dg_batch, start_token=False, end_token=True)\n",
        "        loss = criterian(\n",
        "            dg_predictions.view(-1, dg_vocab_size).to(device),\n",
        "            labels.view(-1).to(device)\n",
        "        ).to(device)\n",
        "        valid_indicies = torch.where(labels.view(-1) == dagaare_to_index[PADDING_TOKEN], False, True)\n",
        "        loss = loss.sum() / valid_indicies.sum()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        #train_losses.append(loss.item())\n",
        "        if batch_num % 100 == 0:\n",
        "            print(f\"Iteration {batch_num} : {loss.item()}\")\n",
        "            print(f\"English: {eng_batch[0]}\")\n",
        "            print(f\"dagaare Translation: {dg_batch[0]}\")\n",
        "            dg_sentence_predicted = torch.argmax(dg_predictions[0], axis=1)\n",
        "            predicted_sentence = \"\"\n",
        "            for idx in dg_sentence_predicted:\n",
        "              if idx == dagaare_to_index[END_TOKEN]:\n",
        "                break\n",
        "              predicted_sentence += index_to_dagaare[idx.item()]\n",
        "            print(f\"dagaare Prediction: {predicted_sentence}\")\n",
        "\n",
        "\n",
        "            transformer.eval()\n",
        "            dg_sentence = (\"\",)\n",
        "            eng_sentence = (\"should we go to the mall?\",)\n",
        "            for word_counter in range(max_sequence_length):\n",
        "                encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask= create_masks(eng_sentence, dg_sentence)\n",
        "                predictions = transformer(eng_sentence,\n",
        "                                          dg_sentence,\n",
        "                                          encoder_self_attention_mask.to(device),\n",
        "                                          decoder_self_attention_mask.to(device),\n",
        "                                          decoder_cross_attention_mask.to(device),\n",
        "                                          enc_start_token=False,\n",
        "                                          enc_end_token=False,\n",
        "                                          dec_start_token=True,\n",
        "                                          dec_end_token=False)\n",
        "                next_token_prob_distribution = predictions[0][word_counter] # not actual probs\n",
        "                next_token_index = torch.argmax(next_token_prob_distribution).item()\n",
        "                next_token = index_to_dagaare[next_token_index]\n",
        "                dg_sentence = (dg_sentence[0] + next_token, )\n",
        "                if next_token == END_TOKEN:\n",
        "                  break\n",
        "\n",
        "            print(f\"Evaluation translation (should we go to the mall?) : {dg_sentence}\")\n",
        "            print(\"-------------------------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "exySsTIKMOnv"
      },
      "outputs": [],
      "source": [
        "transformer.eval()\n",
        "def translate(eng_sentence):\n",
        "  eng_sentence = (eng_sentence,)\n",
        "  dg_sentence = (\"\",)\n",
        "  for word_counter in range(max_sequence_length):\n",
        "    encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask= create_masks(eng_sentence, dg_sentence)\n",
        "    predictions = transformer(eng_sentence,\n",
        "                              dg_sentence,\n",
        "                              encoder_self_attention_mask.to(device),\n",
        "                              decoder_self_attention_mask.to(device),\n",
        "                              decoder_cross_attention_mask.to(device),\n",
        "                              enc_start_token=False,\n",
        "                              enc_end_token=False,\n",
        "                              dec_start_token=True,\n",
        "                              dec_end_token=False)\n",
        "    next_token_prob_distribution = predictions[0][word_counter]\n",
        "    next_token_index = torch.argmax(next_token_prob_distribution).item()\n",
        "    next_token = index_to_dagaare[next_token_index]\n",
        "    dg_sentence = (dg_sentence[0] + next_token, )\n",
        "    if next_token == END_TOKEN:\n",
        "      break\n",
        "  return dg_sentence[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "i2uNnTDzMOlX"
      },
      "outputs": [],
      "source": [
        "translation = translate(\"what should we do when the day starts?\")\n",
        "print(translation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7Yk0qACHMOjG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}